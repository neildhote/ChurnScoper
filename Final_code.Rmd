---
title: "CSP 571 Project -Final"
output: pdf_document
---

```{r Dependencies}
library(plyr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(ggthemes)
library(caret)
library(lattice)
library(MASS)
library(randomForest)
library(party)
library(sandwich)
library(rpart)
library(rattle)
library(GoodmanKruskal)
library(e1071)
library(rpart.plot)
library(caTools)
library(SciViews)
library(class)
library(neuralnet)
library("FactoMineR")
library("factoextra")
```

```{r}
churn_data <- read.csv('data/BankChurners.csv')
```

```{r}
sapply(churn_data, function(x) sum(is.na(x))) # No Nans Awesome
```

```{r feature engineering and removal}

# REMOVE IRRELEVANT COLUMNS


drop <- c("Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1","Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2","CLIENTNUM")
churn_data = churn_data[,!(names(churn_data) %in% drop)]
churn_data[sapply(churn_data, is.character)]<- lapply(churn_data[sapply(churn_data, is.character)], as.factor)
```


```{r}
summary(churn_data)
```

```{r exploratory data analysis}
ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Gender),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)+
  scale_y_continuous(labels = scales::percent)+
  labs(title = "Attrition by Gender",
       x= "Attrition status",
       y="Count")+
  theme_classic()+
  scale_fill_discrete(
    name="Gender",
    breaks=c("M", "F"),
    labels=c("Male", "Female" )
  )

ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Card_Category),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)+
  labs(title = "Attrition by Card Category",
       x= "Attrition status",
       y="Count")+
  theme_classic()

ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Income_Category),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)
  labs(title = "Attrition by Income Category",
       x= "Attrition status",
       y="Count")+
  theme_classic()

ggplot(churn_data, aes(y=Customer_Age,
                  x= Education_Level,
                  fill= factor(Attrition_Flag))) +
  geom_boxplot(position = position_dodge())+
  labs(title = "Attrition Status By Age and Education",
       x= "Education level",
       y="Age")


ggplot(churn_data, aes(Customer_Age))+
  geom_bar(col="red")+ facet_wrap(~Attrition_Flag)+theme_bw()



ggplot(churn_data, aes(Months_on_book))+
  geom_bar(col="blue")+ facet_wrap(~Attrition_Flag)+theme_bw()

ggplot(churn_data, aes(Marital_Status))+
  geom_bar(col="red")+ facet_wrap(~Attrition_Flag)+theme_bw()

ggplot(churn_data, aes(Dependent_count))+
  geom_bar(col="red")+ facet_wrap(~Attrition_Flag)+theme_bw()
```




```{r PCA}

#PCA on numerical columns ## maybe even do MCA for the categorical ones
churn_data.pca_ldg <- pcomp(scale(churn_data[,c(2,4,9:20)]), center = TRUE)
churn_data.pca <- prcomp(scale(churn_data[,c(2,4,9:20)]), center = TRUE)

summary(churn_data.pca)
```


```{r}
screeplot(churn_data.pca_ldg)
(churn_data.ldg <- loadings(churn_data.pca_ldg))
plot(churn_data.pca_ldg, which = "loadings",)
```
```{r}
pc_data <- churn_data.pca$x[,1:10] # pca
cat_data <- churn_data[,c(1,3,5:8)] # getting the categorical columns
mca_data<-MCA(cat_data,ncp=3,graph = TRUE)
fviz_screeplot(mca_data, addlabels = TRUE, ylim = c(0, 45))
fviz_mca_var(mca_data, choice = "mca.cor", 
            repel = TRUE, # Avoid text overlapping (slow)
            ggtheme = theme_minimal())

```




```{r}

churn_pca <-data.frame(cat_data, pc_data)
churn_pca[sapply(churn_pca, is.character)]<- lapply(churn_pca[sapply(churn_pca, is.character)], as.factor)
```

```{r}
# Splitting the PCA DATA

train_indices <- createDataPartition(churn_pca$Attrition_Flag, p = 0.80, list = FALSE)

# Select the rows for training and testing based on the partition created above
training_pca <- churn_pca[train_indices,]
testing_pca <- churn_pca[-train_indices,]

# Print the dimensions of the training and testing datasets to ensure they are split correctly
cat("Training data dimensions:", dim(training_pca), "\n")
cat("Testing data dimensions:", dim(testing_pca), "\n")

# Print summary statistics of the training and testing datasets if desired
# summary(training_pca)
# summary(testing_pca)
```

```{r}
# Splitting the regular dataset

train_indices <- createDataPartition(churn_data$Attrition_Flag, p = 0.80, list = FALSE)


train_data <- churn_data[train_indices,]
test_data <- churn_data[-train_indices,]

# Print the dimensions of the training and testing datasets to ensure they are split correctly
cat("Training data dimensions:", dim(train_data), "\n")
cat("Testing data dimensions:", dim(test_data), "\n")


```




```{r Naive Bayes on PCA}
#

naive_bayes<- naiveBayes(Attrition_Flag ~ ., data= training_pca)
naive_bayes
nb_pred<- predict(naive_bayes, testing_pca)
caret::confusionMatrix(nb_pred, testing_pca$Attrition_Flag)
```

```{r Naive Bayes for regular data}

#

naive_bayes<- naiveBayes(Attrition_Flag ~ ., data= train_data)
naive_bayes
nb_pred<- predict(naive_bayes, test_data)
caret::confusionMatrix(nb_pred, testing_pca$Attrition_Flag)

```














```{r Random Forest for PCA data}
# 

rf_pca <- randomForest(Attrition_Flag ~ ., ntree = 1000, family = "binomial", data = training_pca)


print(summary(rf_pca))


# Predict on test
rf_pca_pred <- predict(rf_pca, testing_pca)

caret::confusionMatrix(rf_pca_pred, test_data$Attrition_Flag)

```

```{r Random Forest for regular data}
# 

rf_reg <- randomForest(Attrition_Flag ~ ., ntree = 1000, family = "binomial", data = train_data)


rf_reg_pred <- predict(rf_reg, test_data)


caret::confusionMatrix(rf_reg_pred, test_data$Attrition_Flag)

```

```{r SVM on Regular data}
#

formula <- Attrition_Flag ~ Customer_Age + Gender + Dependent_count + Education_Level +
  Marital_Status + Income_Category + Card_Category + Months_on_book +
  Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon +
  Credit_Limit + Total_Revolving_Bal + Avg_Open_To_Buy + Total_Amt_Chng_Q4_Q1 +
  Total_Trans_Amt + Total_Trans_Ct + Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio


svm_model <- svm(formula, data=train_data, kernel="radial", cost=1, scale=TRUE)

predictions <- predict(svm_model, newdata=test_data)


accuracy <- sum(predictions == test_data$Attrition_Flag) / length(predictions)
print(paste("Accuracy:", accuracy))


confusion_matrix <- table(Predicted=predictions, Actual=test_data$Attrition_Flag)
print(confusion_matrix)
```


```{r SVM on PCA data}
#


formula <- Attrition_Flag ~ .


svm_model <- svm(formula, data=training_pca, kernel="radial", cost=1, scale=TRUE)

predictions <- predict(svm_model, newdata=testing_pca)


accuracy <- sum(predictions == test_data$Attrition_Flag) / length(predictions)
print(paste("Accuracy:", accuracy))


confusion_matrix <- table(Predicted=predictions, Actual=testing_pca$Attrition_Flag)
print(confusion_matrix)
```










```{r Comparision of different models on PCA Data }
# 


Y = c(0.7847,0.7807,0.8904)
names1 = c("Random Forest","SVM" , "Naive Bayes")
experiment <- data.frame(Algorithm = names1,
                         Percentage = Y)
ggplot(data = experiment, mapping = aes(x=Algorithm, y=Percentage)) + ggtitle("Comparison of Models on PCA data") +
  geom_bar(stat="identity", position = "dodge",fill="lightblue") + scale_fill_brewer(palette = "Pastel2")+
  geom_text(aes(label = Percentage), vjust = -0.2, size = 5,
            position = position_dodge(0.9)) +
  ylim(0, max(experiment$Percentage)*1.1)
```

```{r Comparison of Models on Regular data}

Y = c(0.961,0.925,0.731)
names1 = c("Random Forest","SVM" , "Naive Bayes")
experiment <- data.frame(Algorithm = names1,
                         Percentage = Y)
ggplot(data = experiment, mapping = aes(x=Algorithm, y=Percentage)) + ggtitle("Comparison of Models on Regular data") +
  geom_bar(stat="identity", position = "dodge",fill="lightblue") + scale_fill_brewer(palette = "Pastel2")+
  geom_text(aes(label = Percentage), vjust = -0.2, size = 5,
            position = position_dodge(0.9)) +
  ylim(0, max(experiment$Percentage)*1.1)
```

```{r NEURAL NETWORK TRY THAT FAILED}


#NEURAL NETWORK
train_data_nn <- as.data.frame(sapply(train_data,unclass))

test_data_nn <- as.data.frame(sapply(test_data,unclass))
train_data_nn$Attrition_Flag <- train_data_nn$Attrition_Flag - 1
test_data_nn$Attrition_Flag <- test_data_nn$Attrition_Flag - 1



#val_indices <- createDataPartition(train_data_nn$Attrition_Flag, p = 0.9, list = FALSE)

#val_data_nn <- train_data_nn[-val_indices,]

#names(train_data_nn) <- NULL
#names(val_data_nn) <- NULL
#names(test_data_nn) <- NULL

train_data_nn <- as.data.frame.matrix(train_data_nn)
```










```{r}
library(keras)

model <- keras_model_sequential()%>%
  # Start with a hidden 2D convolutional layer
  layer_dense(19, activation = 'relu',input_shape = c(19,1))%>%
  layer_dense(5, activation = 'relu')%>%
  # Outputs from dense layer
  layer_dense(2, activation = 'softmax')



```



```{r}

opt <- optimizer_adamax(learning_rate = 0.01)

loss <- loss_sparse_categorical_crossentropy(from_logits = TRUE)


model %>% compile(
  loss = loss,
  optimizer = opt,
  metrics = "accuracy"
)
```

```{r}

summary(model)

```

```{r}
history <- model %>% fit(
  train_data_nn[-1,2:20],train_data_nn[-1,1],
  batch_size = 32,
  epochs = 10,
  validation_split=0.1,
  shuffle = TRUE
)
```

