---
title: "CSP 571 Project - Random Forest"
output: pdf_document
---

```{r cars}
library(plyr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(ggthemes)
library(caret)
library(lattice)
library(MASS)
library(randomForest)
library(party)
library(sandwich)
library(rpart)
library(rattle)
library(GoodmanKruskal)
library(e1071)
library(rpart.plot)
library(caTools)
library(SciViews)
library(class)
```

```{r}
churn_data <- read.csv('data/BankChurners.csv')
```

```{r}
sapply(churn_data, function(x) sum(is.na(x))) # No Nans Awesome
```

```{r}

# REMOVE IRRELEVANT COLUMNS


drop <- c("Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1","Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2","CLIENTNUM")
churn_data = churn_data[,!(names(churn_data) %in% drop)]
churn_data[sapply(churn_data, is.character)]<- lapply(churn_data[sapply(churn_data, is.character)], as.factor)
```


```{r}
summary(churn_data)
```

Let's see the 


```{r}
ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Gender),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)+
  scale_y_continuous(labels = scales::percent)+
  labs(title = "Attrition by Gender",
       x= "Attrition status",
       y="Count")+
  theme_classic()+
  scale_fill_discrete(
    name="Gender",
    breaks=c("M", "F"),
    labels=c("Male", "Female" )
  )

ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Card_Category),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)+
  labs(title = "Attrition by Card Category",
       x= "Attrition status",
       y="Count")+
  theme_classic()

ggplot(churn_data, aes(x=Attrition_Flag,
                  y= prop.table(stat(count)),
                  fill= factor(Income_Category),
                  label= scales::percent(prop.table(stat(count))))) +
  geom_bar(position = position_dodge())+
  geom_text(stat="count",
            position = position_dodge(.9),
            vjust= -0.5, size=3)
  labs(title = "Attrition by Income Category",
       x= "Attrition status",
       y="Count")+
  theme_classic()

ggplot(churn_data, aes(y=Customer_Age,
                  x= Education_Level,
                  fill= factor(Attrition_Flag))) +
  geom_boxplot(position = position_dodge())+
  labs(title = "Attrition Status By Age and Education",
       x= "Education level",
       y="Age")

ggplot(churn_data, aes(Months_on_book))+
  geom_bar(col="blue")+ facet_wrap(~Attrition_Flag)+theme_bw()

ggplot(churn_data, aes(Marital_Status))+
  geom_bar(col="red")+ facet_wrap(~Attrition_Flag)+theme_bw()

ggplot(churn_data, aes(Dependent_count))+
  geom_bar(col="red")+ facet_wrap(~Attrition_Flag)+theme_bw()
```






```{r}

#PCA on numerical columns ## maybe even do MCA for the categorical ones
churn_data.pca_ldg <- pcomp(scale(churn_data[,c(2,4,9:20)]), center = TRUE)
churn_data.pca <- prcomp(scale(churn_data[,c(2,4,9:20)]), center = TRUE)

summary(churn_data.pca)
```


```{r}
screeplot(churn_data.pca_ldg)
(churn_data.ldg <- loadings(churn_data.pca_ldg))
plot(churn_data.pca_ldg, which = "loadings",)
```
```{r}
pc_data <- churn_data.pca$x[,1:10]
cat_data <- churn_data[,c(1,3,5:8)]
churn_pca <-data.frame(cat_data, pc_data)
churn_pca[sapply(churn_pca, is.character)]<- lapply(churn_pca[sapply(churn_pca, is.character)], as.factor)
```

```{r}
# Splitting the dataset for PCA analysis
# Create a data partition with 80% of the data for training and 20% for testing
train_indices <- createDataPartition(churn_pca$Attrition_Flag, p = 0.80, list = FALSE)

# Select the rows for training and testing based on the partition created above
training_pca <- churn_pca[train_indices,]
testing_pca <- churn_pca[-train_indices,]

# Print the dimensions of the training and testing datasets to ensure they are split correctly
cat("Training data dimensions:", dim(training_pca), "\n")
cat("Testing data dimensions:", dim(testing_pca), "\n")

# Print summary statistics of the training and testing datasets if desired
# summary(training_pca)
# summary(testing_pca)
```

```{r}
# Splitting the regular dataset
# Create a data partition with 80% of the data for training and 20% for testing
train_indices <- createDataPartition(churn_data$Attrition_Flag, p = 0.80, list = FALSE)

# Select the rows for training and testing based on the partition created above
train_data <- churn_data[train_indices,]
test_data <- churn_data[-train_indices,]

# Print the dimensions of the training and testing datasets to ensure they are split correctly
cat("Training data dimensions:", dim(train_data), "\n")
cat("Testing data dimensions:", dim(test_data), "\n")

# Print summary statistics of the training and testing datasets if desired
# summary(train_data)
# summary(test_data)
```

```{r}
# Random Forest for PCA data
# Train a random forest model with 500 trees using the PCA training dataset
rf_pca <- randomForest(Attrition_Flag ~ ., ntree = 500, family = "binomial", data = train_data)

# Print summary statistics of the random forest model
print(summary(rf_pca))

# Print the random forest model to inspect the model structure and parameters
rf_pca

# Predict the outcomes for the testing dataset using the trained model
rf_pca_pred <- predict(rf_pca, test_data)

# Print confusion matrix to evaluate the performance of the model
caret::confusionMatrix(rf_pca_pred, test_data$Attrition_Flag)


# Random Forest for regular data
# Train a random forest model with 500 trees using the regular training dataset
rf_reg <- randomForest(Attrition_Flag ~ ., ntree = 500, family = "binomial", data = train_data)

# Print summary statistics of the random forest model
print(summary(rf_reg))

# Print the random forest model to inspect the model structure and parameters
rf_reg

# Predict the outcomes for the testing dataset using the trained model
rf_reg_pred <- predict(rf_reg, test_data)

# Print confusion matrix to evaluate the performance of the model
caret::confusionMatrix(rf_reg_pred, test_data$Attrition_Flag)

```

```{r}

```

```{r}

```